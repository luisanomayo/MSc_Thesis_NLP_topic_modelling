{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4835839d-b41b-4d96-a378-ad80d26b3ad8",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h1><b>BERTopic Model: Default Parameters with raw Text</b></h1>\n",
    "</span>\n",
    "<span style = \"font-family: Calibri Light\">\n",
    "    In this model, we used the BerTopic model with default parametes on un-processed text.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b335b7-cd30-482c-b2d2-7feff17e182b",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h2><b>I. Setup Environment</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4918b212-91f2-482b-ba89-124b79f78f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['PATH'] = \"/home/ec2-user/.local/bin:\" + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66a0feb4-81f0-435c-98bd-01817973410b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting bertopic\n",
      "  Obtaining dependency information for bertopic from https://files.pythonhosted.org/packages/06/49/f395e2e4d21dd49803494c8aec6087db61ea0ba211c6e5e57540b23334eb/bertopic-0.15.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading bertopic-0.15.0-py2.py3-none-any.whl.metadata (20 kB)\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.2.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.20.0 in /usr/local/lib64/python3.7/site-packages (from bertopic) (1.21.5)\n",
      "Collecting hdbscan>=0.8.29 (from bertopic)\n",
      "  Downloading hdbscan-0.8.33.tar.gz (5.2 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting umap-learn>=0.5.0 (from bertopic)\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pandas>=1.1.5 in /usr/local/lib64/python3.7/site-packages (from bertopic) (1.3.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib64/python3.7/site-packages (from bertopic) (1.0.2)\n",
      "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/site-packages (from bertopic) (4.62.3)\n",
      "Collecting sentence-transformers>=0.4.1 (from bertopic)\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m883.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting plotly>=4.7.0 (from bertopic)\n",
      "  Obtaining dependency information for plotly>=4.7.0 from https://files.pythonhosted.org/packages/df/79/c80174d711ee26ee5da55a9cc3e248f1ec7a0188b5e4d6bbbbcd09b974b0/plotly-5.17.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading plotly-5.17.0-py2.py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib64/python3.7/site-packages (from gensim) (1.7.3)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Obtaining dependency information for smart-open>=1.8.1 from https://files.pythonhosted.org/packages/fc/d9/d97f1db64b09278aba64e8c81b5d322d436132df5741c518f3823824fae0/smart_open-6.4.0-py3-none-any.whl.metadata\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: cython<3,>=0.27 in /usr/local/lib64/python3.7/site-packages (from hdbscan>=0.8.29->bertopic) (0.29.27)\n",
      "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/site-packages (from hdbscan>=0.8.29->bertopic) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/site-packages (from pandas>=1.1.5->bertopic) (2021.3)\n",
      "Collecting tenacity>=6.2.0 (from plotly>=4.7.0->bertopic)\n",
      "  Obtaining dependency information for tenacity>=6.2.0 from https://files.pythonhosted.org/packages/f4/f1/990741d5bb2487d529d20a433210ffa136a367751e454214013b441c4575/tenacity-8.2.3-py3-none-any.whl.metadata\n",
      "  Downloading tenacity-8.2.3-py3-none-any.whl.metadata (1.0 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.7/site-packages (from plotly>=4.7.0->bertopic) (21.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/site-packages (from scikit-learn>=0.22.2.post1->bertopic) (3.1.0)\n",
      "Collecting transformers<5.0.0,>=4.6.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Obtaining dependency information for transformers<5.0.0,>=4.6.0 from https://files.pythonhosted.org/packages/5b/0b/e45d26ccd28568013523e04f325432ea88a442b4e3020b757cf4361f0120/transformers-4.30.2-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.30.2-py3-none-any.whl.metadata (113 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m113.6/113.6 kB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib64/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib64/python3.7/site-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.2)\n",
      "Collecting nltk (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading sentencepiece-0.1.99-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0 (from sentence-transformers>=0.4.1->bertopic)\n",
      "  Obtaining dependency information for huggingface-hub>=0.4.0 from https://files.pythonhosted.org/packages/7f/c4/adcbe9a696c135578cabcbdd7331332daad4d49b7c43688bc2d36b3a47d2/huggingface_hub-0.16.4-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.16.4-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting numba>=0.51.2 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading numba-0.56.4-cp37-cp37m-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.5 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pynndescent>=0.5 (from umap-learn>=0.5.0->bertopic)\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tbb>=2019.0 (from umap-learn>=0.5.0->bertopic)\n",
      "  Obtaining dependency information for tbb>=2019.0 from https://files.pythonhosted.org/packages/79/a8/01ac205ff1f68f543aa73d69d6947218cd0973992a4b60cf0a4bfe507561/tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl.metadata\n",
      "  Downloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/00/45/ec3407adf6f6b5bf867a4462b2b0af27597a26bd3cd6e2534cb6ab029938/filelock-3.12.2-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.12.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting fsspec (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading fsspec-2023.1.0-py3-none-any.whl (143 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib64/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.7.1)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/site-packages (from huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (4.10.1)\n",
      "Collecting llvmlite<0.40,>=0.39.0dev0 (from numba>=0.51.2->umap-learn>=0.5.0->bertopic)\n",
      "  Downloading llvmlite-0.39.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.6 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m34.6/34.6 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/site-packages (from numba>=0.51.2->umap-learn>=0.5.0->bertopic) (60.8.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/site-packages (from packaging->plotly>=4.7.0->bertopic) (3.0.7)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas>=1.1.5->bertopic) (1.16.0)\n",
      "Collecting regex!=2019.12.17 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/63/78/ed291d95116695b8b5d7469a931d7c2e83d942df0853915ee504cee98bcf/regex-2023.8.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading regex-2023.8.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Downloading tokenizers-0.13.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m71.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic)\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/a2/04/e55780fcb9e1a1e4bf22b881146087d9b13f60b9ab1a30c773dd398d5f65/safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from nltk->sentence-transformers>=0.4.1->bertopic) (8.0.3)\n",
      "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib64/python3.7/site-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.7.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2.0.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
      "Downloading bertopic-0.15.0-py2.py3-none-any.whl (143 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m143.4/143.4 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading plotly-5.17.0-py2.py3-none-any.whl (15.6 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m15.6/15.6 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m107.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.2.3-py3-none-any.whl (24 kB)\n",
      "Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading regex-2023.8.8-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (758 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m759.0/759.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading safetensors-0.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading filelock-3.12.2-py3-none-any.whl (10 kB)\n",
      "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
      "  Building wheel for hdbscan (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdbscan: filename=hdbscan-0.8.33-cp37-cp37m-linux_x86_64.whl size=2337954 sha256=5f8308da168b0a878c2a31d9e219096efad09480309d8fda113cec7767b86f3c\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/af/1f/71/ad36cf482247fc0725b271e8ce10f9ee5f84414d1783c875b2\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125940 sha256=a2aa9cc55e962a720b7b9d9ee7bd4aa1ddb3abf627cfa8a5378ecd191b28f3b4\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/bf/06/fb/d59c1e5bd1dac7f6cf61ec0036cc3a10ab8fecaa6b2c3d3ee9\n",
      "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86794 sha256=85d50f165f9ba72c1060cdeabcbe6a95547d3b6961cd5f056f83e5ad9f9d8464\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/6f/40/5b/53326040d43108786ba65048baae2a4e8e5f4e69f9d9842c32\n",
      "  Building wheel for pynndescent (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55638 sha256=0289b3fd3267b54b11585d5ba0e163f48bbf11f6ab4c11e10921869cda9b8195\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/e1/38/f7/4d18bfa0426d0a999e6fb3ed8622298ea40b3ba807f903cd02\n",
      "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
      "Installing collected packages: tokenizers, tbb, sentencepiece, safetensors, tenacity, smart-open, regex, llvmlite, fsspec, filelock, plotly, numba, huggingface-hub, gensim, transformers, pynndescent, nltk, hdbscan, umap-learn, sentence-transformers, bertopic\n",
      "Successfully installed bertopic-0.15.0 filelock-3.12.2 fsspec-2023.1.0 gensim-4.2.0 hdbscan-0.8.33 huggingface-hub-0.16.4 llvmlite-0.39.1 nltk-3.8.1 numba-0.56.4 plotly-5.17.0 pynndescent-0.5.10 regex-2023.8.8 safetensors-0.3.3 sentence-transformers-2.2.2 sentencepiece-0.1.99 smart-open-6.4.0 tbb-2021.10.0 tenacity-8.2.3 tokenizers-0.13.3 transformers-4.30.2 umap-learn-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install bertopic gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b13175c5-f665-408c-88e8-a9ae9e591a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-24 05:05:31.333735: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-24 05:05:42.582639: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-24 05:06:29.134581: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-24 05:06:29.135076: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-24 05:06:29.135085: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import ast\n",
    "import csv\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "from collections import Counter\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "#NLP libraries\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import tokenize\n",
    "from gensim.models.phrases import Phrases\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "\n",
    "from bertopic import BERTopic\n",
    "from bertopic.representation import MaximalMarginalRelevance, KeyBERTInspired\n",
    "from bertopic.vectorizers import  ClassTfidfTransformer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "#for vis\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = 'iframe'\n",
    "\n",
    "from umap import UMAP\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "from hdbscan import HDBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02bb3fab-d945-4078-ade0-03894b0f6ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(580)  # Set the seed for Python's random module\n",
    "np.random.seed(580)  # Set the seed for NumPy's random module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6e4385-c2e4-4285-ac07-b0349ecbb2a0",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h2><b>II. Load and Pre-process Data</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12bcf8d3-fa5e-4c5e-914e-88761e651963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../Data/comments.csv',\n",
       " '../../Data/emoji_subset.csv',\n",
       " '../../Data/full_posts.csv',\n",
       " '../../Data/bert_train_lemma.csv',\n",
       " '../../Data/bert_train_no_prep.csv',\n",
       " '../../Data/full_data_no_preprocessing.csv',\n",
       " '../../Data/subset_sample_no_label.csv',\n",
       " '../../Data/test_data_lemma.csv',\n",
       " '../../Data/bert-data-sw.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#access dataset files\n",
    "folder_path = os.path.join(\"..\", \"../Data\")\n",
    "file_type = \"*.csv\"\n",
    "\n",
    "#list of dataset file paths\n",
    "document_path = glob(os.path.join(folder_path, file_type))\n",
    "\n",
    "document_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff592e7d-1d57-48c1-80cf-5281f1b59c6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfo2hl</td>\n",
       "      <td>2021-04-05 13:00:32</td>\n",
       "      <td>2021</td>\n",
       "      <td>*Cuntry roads, take me hoem*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfqkbv</td>\n",
       "      <td>2021-04-05 13:41:40</td>\n",
       "      <td>2021</td>\n",
       "      <td>Thatâ€™s been there for several years, sent a pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfou07</td>\n",
       "      <td>2021-04-05 13:13:23</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am single and I have not traveled to any cun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtfrgpe</td>\n",
       "      <td>2021-04-05 13:56:09</td>\n",
       "      <td>2021</td>\n",
       "      <td>What happens when you shop at dragon mart...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>gtg5mwv</td>\n",
       "      <td>2021-04-05 16:51:54</td>\n",
       "      <td>2021</td>\n",
       "      <td>I am cunting on them to do so ğŸ˜…</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID         date_created  year  \\\n",
       "0   comment  gtfo2hl  2021-04-05 13:00:32  2021   \n",
       "1   comment  gtfqkbv  2021-04-05 13:41:40  2021   \n",
       "2   comment  gtfou07  2021-04-05 13:13:23  2021   \n",
       "3   comment  gtfrgpe  2021-04-05 13:56:09  2021   \n",
       "4   comment  gtg5mwv  2021-04-05 16:51:54  2021   \n",
       "\n",
       "                                           long_text  \n",
       "0                       *Cuntry roads, take me hoem*  \n",
       "1  Thatâ€™s been there for several years, sent a pi...  \n",
       "2  I am single and I have not traveled to any cun...  \n",
       "3       What happens when you shop at dragon mart...  \n",
       "4                    I am cunting on them to do so ğŸ˜…  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import cleaned data\n",
    "\n",
    "def list_converter(text):\n",
    "    #to revert list->str conversion from pd.read_csv\n",
    "    return ast.literal_eval(text)\n",
    "\n",
    "\n",
    "train_data = pd.read_csv('../../Data/bert_train_no_prep.csv', converters ={'tokens':list_converter})\n",
    "train_data = train_data.drop(columns = ['index'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6ff53e0-3a7b-4e24-9931-78190b4e9f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 127686 entries, 0 to 127685\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   text_type     127686 non-null  object\n",
      " 1   ID            127686 non-null  object\n",
      " 2   date_created  127686 non-null  object\n",
      " 3   year          127686 non-null  int64 \n",
      " 4   long_text     127686 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "#sort by data created\n",
    "train_data.sort_values(by='date_created', inplace = True, ignore_index = True)\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4e93d18-ff0e-4f56-b3ad-fbdfef58a82b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>c5c54q4</td>\n",
       "      <td>2012-07-11 00:50:58</td>\n",
       "      <td>2012</td>\n",
       "      <td>That dessert's a bit rich for me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>c5edn0u</td>\n",
       "      <td>2012-07-15 21:59:34</td>\n",
       "      <td>2012</td>\n",
       "      <td>\"A SILVER one?! I HATE YOU DAD!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d18gk</td>\n",
       "      <td>2012-09-25 07:57:13</td>\n",
       "      <td>2012</td>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d1cs1</td>\n",
       "      <td>2012-09-25 08:04:04</td>\n",
       "      <td>2012</td>\n",
       "      <td>seriously?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d2fss</td>\n",
       "      <td>2012-09-25 09:13:23</td>\n",
       "      <td>2012</td>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID         date_created  year  \\\n",
       "0   comment  c5c54q4  2012-07-11 00:50:58  2012   \n",
       "1   comment  c5edn0u  2012-07-15 21:59:34  2012   \n",
       "2   comment  c6d18gk  2012-09-25 07:57:13  2012   \n",
       "3   comment  c6d1cs1  2012-09-25 08:04:04  2012   \n",
       "4   comment  c6d2fss  2012-09-25 09:13:23  2012   \n",
       "\n",
       "                                           long_text  \n",
       "0                  That dessert's a bit rich for me.  \n",
       "1                  \"A SILVER one?! I HATE YOU DAD!\"   \n",
       "2  Yet i stared at the picture for a good 45 seco...  \n",
       "3                                         seriously?  \n",
       "4  [FYSR] = from your sister subreddit.\\n\\nIMO, i...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992be478-3e13-4688-9664-3ba56869c670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text_type, ID, date_created, year, long_text]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for empty values\n",
    "train_data[train_data['long_text'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831008ab-0bd6-4f81-8e33-59fa94c35e2a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f9d806-b8a2-4452-a6e1-575bec63a4d9",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h2><b>III. Train Model</b></h2>\n",
    "</span>\n",
    "<p>First, we will train the model using different nr_topics (5,10,15,20,30,50) and compare their performance using quantitative measures such as coherence and topic diversity. Also, introduce larger min_cluster in the HDBSCAN model to reduce the presence of outliers.<br>\n",
    "Coherence we will measure with 'c_v' and 'c_npmi', and topic diversity, we will measure uniqueness and exclusivity.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a98adbe0-04ec-459f-8d89-099c2a876678",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare data for bertopic model\n",
    "docs = train_data['long_text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5f78a7b-2978-4d7f-842c-f8110814752a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf780a085514189b37628336c1a15b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)e9125/.gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7532575360f4615b7b05098acd5078f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c09626ef204493b8c2d78c1d0baefa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)7e55de9125/README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb62a468c65e4a11a8f596b27430a509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)55de9125/config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7830af49ab34d0481f53d82e81baf7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)ce_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "991e0692985a49c49417796abaa828aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)125/data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bc9e97a9c04585a1d7df76b5f57daa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bde3c62ec6e4cee8c0184d66d005df3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "358f4f1226ea4994aa2c7fc9fd9be4fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c17378fbca24d1fb3475a7d09dfecf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)e9125/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eeac7cf266e41d2a253d6b1e03ca00c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)okenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8fcc5151734807b1e3ef10d34f5e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)9125/train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9b9f032fc9044ccbdd8e3631e9e3b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)7e55de9125/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cfa3bf85d964f7ab9685fd18bd51c13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)5de9125/modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da2daae77104dccab7ccdf3ce82c33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3991 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prepaer sub-models\n",
    "umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=182)\n",
    "hdbscan_model = HDBSCAN(min_cluster_size = 80, min_samples = 10, metric = 'euclidean', prediction_data = True)\n",
    "vectorizer_model = CountVectorizer(stop_words=\"english\")\n",
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "embeddings = sentence_model.encode(docs, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b98280a-c12d-4c03-8b5c-9433829fc7ad",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "For 5 topics:\n",
      "Coherence(c_v) = 0.42309061197857717,\n",
      "Coherence(c_npmi) = -0.051551545299920676,\n",
      "Topic Diversity-Uniquesness = 0.6,\n",
      "Topic Diversity-Exclusivity = 0.4\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "For 10 topics:\n",
      "Coherence(c_v) = 0.37280873233654765,\n",
      "Coherence(c_npmi) = -0.07494947090021366,\n",
      "Topic Diversity-Uniquesness = 0.67,\n",
      "Topic Diversity-Exclusivity = 0.57\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "For 15 topics:\n",
      "Coherence(c_v) = 0.40416646957408986,\n",
      "Coherence(c_npmi) = -0.0684405524601204,\n",
      "Topic Diversity-Uniquesness = 0.7666666666666667,\n",
      "Topic Diversity-Exclusivity = 0.6866666666666666\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "For 20 topics:\n",
      "Coherence(c_v) = 0.39093812482358914,\n",
      "Coherence(c_npmi) = -0.0811848649964242,\n",
      "Topic Diversity-Uniquesness = 0.82,\n",
      "Topic Diversity-Exclusivity = 0.745\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "For 25 topics:\n",
      "Coherence(c_v) = 0.3957281399533411,\n",
      "Coherence(c_npmi) = -0.08298413264009782,\n",
      "Topic Diversity-Uniquesness = 0.844,\n",
      "Topic Diversity-Exclusivity = 0.756\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "For 50 topics:\n",
      "Coherence(c_v) = 0.4422121243633128,\n",
      "Coherence(c_npmi) = -0.04406355470777424,\n",
      "Topic Diversity-Uniquesness = 0.896,\n",
      "Topic Diversity-Exclusivity = 0.82\n",
      "This code took 28.87 minutes to execute\n"
     ]
    }
   ],
   "source": [
    "#train bert models\n",
    "\n",
    "topic_range = [5,10,15,20,25,50]\n",
    "cv_scores = []\n",
    "cnpmi_scores = []\n",
    "topic_uniqueness = []\n",
    "topic_exclusivity = []\n",
    "#loop over topics_range and calculate topic coherence and topic diversity\n",
    "\n",
    "start_time = time.time()\n",
    "for num_topics in topic_range:\n",
    "    #train bertopic model\n",
    "    model = BERTopic(embedding_model=sentence_model, umap_model=umap_model, \n",
    "                 hdbscan_model = hdbscan_model,vectorizer_model=vectorizer_model, \n",
    "                nr_topics = num_topics)\n",
    "    \n",
    "    topics,_ = model.fit_transform(docs, embeddings)\n",
    "    \n",
    "    #calculate coherence score(c_v)\n",
    "    topic_reps = model.get_topic_info()\n",
    "    dictionary = Dictionary([words.split() for words in docs])\n",
    "    corpus = [dictionary.doc2bow(doc.split()) for doc in docs]\n",
    "    cv = CoherenceModel(topics = topic_reps['Representation'].tolist(),\n",
    "                       texts = [doc.split() for doc in train_data['long_text'].values],\n",
    "                        dictionary = dictionary, coherence = 'c_v')\n",
    "    cv_coherence =cv.get_coherence()\n",
    "    cv_scores.append(cv_coherence)\n",
    "    \n",
    "    #calculate coherence score(c_npmi)\n",
    "    cnpmi = CoherenceModel(topics = topic_reps['Representation'].tolist(),\n",
    "                       texts = [doc.split() for doc in train_data['long_text'].values],\n",
    "                        dictionary = dictionary, coherence = 'c_npmi')\n",
    "    cnpmi_coherence =cnpmi.get_coherence()\n",
    "    cnpmi_scores.append(cnpmi_coherence)\n",
    "    \n",
    "    #calculate topic diversity - exclusivity\n",
    "    n = 10\n",
    "    #unique topics\n",
    "    unique_topics = model.get_topic_freq()['Topic'].tolist()\n",
    "    #remove outlier topics\n",
    "    unique_topics = [topic for topic in unique_topics if topics != -1]\n",
    "    #get top_n words for each topic\n",
    "    topic_words = [model.get_topic(topic_id)[:n] for topic_id in unique_topics]\n",
    "    all_top_words = [word for topic in topic_words for word,_ in topic]\n",
    "    #calculate exclusivity\n",
    "    word_counts = Counter(all_top_words)\n",
    "    exclusivity = sum(1 for word, count in word_counts.items() if count == 1)/ len(all_top_words)\n",
    "    topic_exclusivity.append(exclusivity)\n",
    "    #calculate topic diversity - uniqueness\n",
    "    uniqueness = len(set(all_top_words))/ (n * len(unique_topics))\n",
    "    topic_uniqueness.append(uniqueness)\n",
    "    \n",
    "    \n",
    "    print(f\"For {num_topics} topics:\\nCoherence(c_v) = {cv_coherence},\\nCoherence(c_npmi) = {cnpmi_coherence},\\nTopic Diversity-Uniquesness = {uniqueness},\\nTopic Diversity-Exclusivity = {exclusivity}\")\n",
    "    \n",
    "print(f\"This code took {(time.time() - start_time)/60 :.2f} minutes to execute\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47fb48bb-fc60-4f44-a71f-a39bd0a470ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>coherence(c_v)</th>\n",
       "      <th>coherence(c_npmi)</th>\n",
       "      <th>topic_diveristy_uniqueness</th>\n",
       "      <th>topic_diversity_exclusivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>0.423091</td>\n",
       "      <td>-0.051552</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.372809</td>\n",
       "      <td>-0.074949</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.570000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0.404166</td>\n",
       "      <td>-0.068441</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.686667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>0.390938</td>\n",
       "      <td>-0.081185</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.745000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>0.395728</td>\n",
       "      <td>-0.082984</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.756000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50</td>\n",
       "      <td>0.442212</td>\n",
       "      <td>-0.044064</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   topics  coherence(c_v)  coherence(c_npmi)  topic_diveristy_uniqueness  \\\n",
       "0       5        0.423091          -0.051552                    0.600000   \n",
       "1      10        0.372809          -0.074949                    0.670000   \n",
       "2      15        0.404166          -0.068441                    0.766667   \n",
       "3      20        0.390938          -0.081185                    0.820000   \n",
       "4      25        0.395728          -0.082984                    0.844000   \n",
       "5      50        0.442212          -0.044064                    0.896000   \n",
       "\n",
       "   topic_diversity_exclusivity  \n",
       "0                     0.400000  \n",
       "1                     0.570000  \n",
       "2                     0.686667  \n",
       "3                     0.745000  \n",
       "4                     0.756000  \n",
       "5                     0.820000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = {'topics': topic_range,'coherence(c_v)': cv_scores, 'coherence(c_npmi)':cnpmi_scores, 'topic_diveristy_uniqueness':topic_uniqueness, 'topic_diversity_exclusivity': topic_exclusivity}\n",
    "bert_default_raw_text_eval = pd.DataFrame(evals)\n",
    "\n",
    "bert_default_raw_text_eval.to_csv('bert_default_raw_text_evals.csv')\n",
    "bert_default_raw_text_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aaa6937-b2f5-4c0a-bd6f-b520968a8177",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_eval = pd.read_csv('bert_default_raw_text_evals.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4a6852c-b8c4-4952-83aa-5eb1ef4229ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "fig.suptitle('Optimization of BERTopic, default params, with raw text', fontsize=16, y=1.08)\n",
    "\n",
    "# Plot coherence scores\n",
    "ax1 = plt.subplot(1, 2, 1)\n",
    "ax1.plot(model_eval['topics'], model_eval['coherence(c_v)'], marker='o', label = 'c_v')\n",
    "ax1.plot(model_eval['topics'], model_eval['coherence(c_npmi)'], marker='o', label = 'c_npmi')\n",
    "ax1.title.set_text('Coherence Scores')\n",
    "ax1.legend()\n",
    "ax1.set_xlabel('Number of Topics')\n",
    "ax1.set_ylabel('Coherence (c_v)')\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "\n",
    "# Plot topic diversities\n",
    "ax2 = plt.subplot(1, 2, 2)\n",
    "ax2.plot(model_eval['topics'], model_eval['topic_diveristy_uniqueness'], marker='o', label = 'unq')\n",
    "ax2.plot(model_eval['topics'], model_eval['topic_diversity_exclusivity'], marker='o', label = 'excl')\n",
    "ax2.title.set_text('Topic Diversities')\n",
    "ax2.legend()\n",
    "ax2.set_xlabel('Number of Topics')\n",
    "ax2.set_ylabel('Diversity')\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the figure\n",
    "fig.savefig('bertopic_default_params_raw_text_optimization.png', bbox_inches='tight', dpi=300)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c88405-890f-4da8-a166-4eadc54e97a0",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h2><b>IV. Select Optimal Model</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f0b8e29-2772-480b-8d3b-89d510c1e1ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "This project took 4.28 minutes to complete\n"
     ]
    }
   ],
   "source": [
    "# Prepare data, extract embeddings, and prepare sub-models\n",
    "#docs = train_data['long_text'].values\n",
    "\n",
    "#umap_model = UMAP(n_neighbors=15, n_components=5, min_dist=0.0, metric='cosine', random_state=142)\n",
    "#hdbscan_model = HDBSCAN(min_cluster_size = 80, min_samples = 10, metric = 'euclidean', prediction_data = True)\n",
    "#vectorizer_model = CountVectorizer(stop_words=\"english\", ngram_range=(1,2), max_df = 0.75, min_df = 10)\n",
    "#sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "#embeddings = sentence_model.encode(docs, show_progress_bar=True)\n",
    "#representation_model = MaximalMarginalRelevance(diversity = 0.8)\n",
    "\n",
    "\n",
    "# We reduce our embeddings to 2D as it will allows us to quickly iterate later on\n",
    "reduced_embeddings = UMAP(n_neighbors=10, n_components=2, \n",
    "                          min_dist=0.0, metric='cosine').fit_transform(embeddings)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Train our topic model\n",
    "model = BERTopic(embedding_model=sentence_model, umap_model=umap_model, \n",
    "                 hdbscan_model = hdbscan_model,vectorizer_model=vectorizer_model,\n",
    "                 nr_topics=50)\n",
    "\n",
    "topics = model.fit_transform(docs, embeddings)\n",
    "print (f\"This project took {(time.time() - start_time)/60 :.2f} minutes to complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "656bbc4f-b615-4ab3-b4ca-dd53f397a0cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model saved\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "model.save(\"bertopic_models/model1_default_raw_text_\")\n",
    "print ('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1df2dfef-b2ee-4fc1-b9d0-8025c15e747a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model\n",
    "model = BERTopic.load(\"../bertopic_models/model1_default_raw_text_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ba5efa88-9274-468d-9b99-8d3c8925e066",
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_df = model.get_topic_info()\n",
    "topics_df.to_csv('bert_default_raw_text_topics_term.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78063d69-1eb9-4d51-b58d-efa495533d7b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>62587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>10724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3</td>\n",
       "      <td>2574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>2532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>2202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>2037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>9</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10</td>\n",
       "      <td>1973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>12</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>13</td>\n",
       "      <td>1372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>14</td>\n",
       "      <td>1277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>16</td>\n",
       "      <td>1160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17</td>\n",
       "      <td>1095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>18</td>\n",
       "      <td>1067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>19</td>\n",
       "      <td>1064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>21</td>\n",
       "      <td>947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>22</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>23</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>24</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>25</td>\n",
       "      <td>734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>26</td>\n",
       "      <td>707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>27</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28</td>\n",
       "      <td>667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>29</td>\n",
       "      <td>611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>30</td>\n",
       "      <td>583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>31</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>32</td>\n",
       "      <td>441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>33</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>34</td>\n",
       "      <td>321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>35</td>\n",
       "      <td>294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>36</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>38</td>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>39</td>\n",
       "      <td>238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>40</td>\n",
       "      <td>223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>41</td>\n",
       "      <td>204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>42</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>44</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>45</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>47</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>48</td>\n",
       "      <td>103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Topic  Count\n",
       "0      -1  62587\n",
       "2       0  10724\n",
       "1       1   7332\n",
       "4       2   4844\n",
       "17      3   2574\n",
       "18      4   2532\n",
       "3       5   2528\n",
       "13      6   2202\n",
       "6       7   2094\n",
       "24      8   2037\n",
       "23      9   2005\n",
       "29     10   1973\n",
       "11     11   1712\n",
       "25     12   1420\n",
       "32     13   1372\n",
       "35     14   1277\n",
       "14     15   1272\n",
       "21     16   1160\n",
       "7      17   1095\n",
       "15     18   1067\n",
       "43     19   1064\n",
       "26     20   1050\n",
       "16     21    947\n",
       "10     22    825\n",
       "46     23    808\n",
       "39     24    747\n",
       "30     25    734\n",
       "5      26    707\n",
       "8      27    679\n",
       "36     28    667\n",
       "45     29    611\n",
       "12     30    583\n",
       "20     31    572\n",
       "37     32    441\n",
       "40     33    349\n",
       "27     34    321\n",
       "34     35    294\n",
       "42     36    286\n",
       "9      37    263\n",
       "38     38    249\n",
       "28     39    238\n",
       "47     40    223\n",
       "19     41    204\n",
       "31     42    202\n",
       "22     43    198\n",
       "41     44    141\n",
       "49     45    136\n",
       "44     46    124\n",
       "33     47    113\n",
       "48     48    103"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_freq = model.get_topic_freq()\n",
    "top_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "793f8418-7632-4040-99c2-b7a51e97e763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"520\"\n",
       "    src=\"iframe_figures/figure_10.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.visualize_barchart(topics = [3,24,6,10, 25,4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e847879-5f8d-42c5-afab-5e1b663ef64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe\n",
       "    scrolling=\"no\"\n",
       "    width=\"1020px\"\n",
       "    height=\"3270\"\n",
       "    src=\"iframe_figures/figure_11.html\"\n",
       "    frameborder=\"0\"\n",
       "    allowfullscreen\n",
       "></iframe>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.visualize_barchart(top_n_topics = 50, n_words = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e2dec1-142e-47e7-81c0-0617d93d9dfc",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-family: Calibri Light;\">\n",
    "  <h2><b>V. Retrieve Data with Topic Assignments</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfcf31ea-8086-429b-840e-fb80d6a151fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Representation</th>\n",
       "      <th>Representative_Docs</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>That dessert's a bit rich for me.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "      <td>[dubai, people, just, like, don, uae, know, ti...</td>\n",
       "      <td>[I'm in Toronto and have already bought a hous...</td>\n",
       "      <td>dubai - people - just - like - don - uae - kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"A SILVER one?! I HATE YOU DAD!\"</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "      <td>[dubai, people, just, like, don, uae, know, ti...</td>\n",
       "      <td>[I'm in Toronto and have already bought a hous...</td>\n",
       "      <td>dubai - people - just - like - don - uae - kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "      <td>[dubai, people, just, like, don, uae, know, ti...</td>\n",
       "      <td>[I'm in Toronto and have already bought a hous...</td>\n",
       "      <td>dubai - people - just - like - don - uae - kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>seriously?</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "      <td>[dubai, people, just, like, don, uae, know, ti...</td>\n",
       "      <td>[I'm in Toronto and have already bought a hous...</td>\n",
       "      <td>dubai - people - just - like - don - uae - kno...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_dubai_uae_arabic_people</td>\n",
       "      <td>[dubai, uae, arabic, people, sharjah, country,...</td>\n",
       "      <td>[Putting social life aside, Dubai is pretty co...</td>\n",
       "      <td>dubai - uae - arabic - people - sharjah - coun...</td>\n",
       "      <td>0.779326</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0                  That dessert's a bit rich for me.     -1   \n",
       "1                  \"A SILVER one?! I HATE YOU DAD!\"      -1   \n",
       "2  Yet i stared at the picture for a good 45 seco...     -1   \n",
       "3                                         seriously?     -1   \n",
       "4  [FYSR] = from your sister subreddit.\\n\\nIMO, i...      1   \n",
       "\n",
       "                        Name  \\\n",
       "0  -1_dubai_people_just_like   \n",
       "1  -1_dubai_people_just_like   \n",
       "2  -1_dubai_people_just_like   \n",
       "3  -1_dubai_people_just_like   \n",
       "4  1_dubai_uae_arabic_people   \n",
       "\n",
       "                                      Representation  \\\n",
       "0  [dubai, people, just, like, don, uae, know, ti...   \n",
       "1  [dubai, people, just, like, don, uae, know, ti...   \n",
       "2  [dubai, people, just, like, don, uae, know, ti...   \n",
       "3  [dubai, people, just, like, don, uae, know, ti...   \n",
       "4  [dubai, uae, arabic, people, sharjah, country,...   \n",
       "\n",
       "                                 Representative_Docs  \\\n",
       "0  [I'm in Toronto and have already bought a hous...   \n",
       "1  [I'm in Toronto and have already bought a hous...   \n",
       "2  [I'm in Toronto and have already bought a hous...   \n",
       "3  [I'm in Toronto and have already bought a hous...   \n",
       "4  [Putting social life aside, Dubai is pretty co...   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  dubai - people - just - like - don - uae - kno...     0.000000   \n",
       "1  dubai - people - just - like - don - uae - kno...     0.000000   \n",
       "2  dubai - people - just - like - don - uae - kno...     0.000000   \n",
       "3  dubai - people - just - like - don - uae - kno...     0.000000   \n",
       "4  dubai - uae - arabic - people - sharjah - coun...     0.779326   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create dataframe with topic assignments\n",
    "t_df = model.get_document_info(docs)\n",
    "t_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a80b32c4-0b98-42ad-985e-45ede7e3f81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_label = train_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7587349-1813-4421-ac5c-39f003e5707d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_label[['Topic', 'Name']] = t_df[['Topic', 'Name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59053d73-9bec-43de-8b1e-94fb943cb41c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_type</th>\n",
       "      <th>ID</th>\n",
       "      <th>date_created</th>\n",
       "      <th>year</th>\n",
       "      <th>long_text</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>comment</td>\n",
       "      <td>c5c54q4</td>\n",
       "      <td>2012-07-11 00:50:58</td>\n",
       "      <td>2012</td>\n",
       "      <td>That dessert's a bit rich for me.</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>comment</td>\n",
       "      <td>c5edn0u</td>\n",
       "      <td>2012-07-15 21:59:34</td>\n",
       "      <td>2012</td>\n",
       "      <td>\"A SILVER one?! I HATE YOU DAD!\"</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d18gk</td>\n",
       "      <td>2012-09-25 07:57:13</td>\n",
       "      <td>2012</td>\n",
       "      <td>Yet i stared at the picture for a good 45 seco...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d1cs1</td>\n",
       "      <td>2012-09-25 08:04:04</td>\n",
       "      <td>2012</td>\n",
       "      <td>seriously?</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_dubai_people_just_like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>comment</td>\n",
       "      <td>c6d2fss</td>\n",
       "      <td>2012-09-25 09:13:23</td>\n",
       "      <td>2012</td>\n",
       "      <td>[FYSR] = from your sister subreddit.\\n\\nIMO, i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1_dubai_uae_arabic_people</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  text_type       ID         date_created  year  \\\n",
       "0   comment  c5c54q4  2012-07-11 00:50:58  2012   \n",
       "1   comment  c5edn0u  2012-07-15 21:59:34  2012   \n",
       "2   comment  c6d18gk  2012-09-25 07:57:13  2012   \n",
       "3   comment  c6d1cs1  2012-09-25 08:04:04  2012   \n",
       "4   comment  c6d2fss  2012-09-25 09:13:23  2012   \n",
       "\n",
       "                                           long_text  Topic  \\\n",
       "0                  That dessert's a bit rich for me.     -1   \n",
       "1                  \"A SILVER one?! I HATE YOU DAD!\"      -1   \n",
       "2  Yet i stared at the picture for a good 45 seco...     -1   \n",
       "3                                         seriously?     -1   \n",
       "4  [FYSR] = from your sister subreddit.\\n\\nIMO, i...      1   \n",
       "\n",
       "                        Name  \n",
       "0  -1_dubai_people_just_like  \n",
       "1  -1_dubai_people_just_like  \n",
       "2  -1_dubai_people_just_like  \n",
       "3  -1_dubai_people_just_like  \n",
       "4  1_dubai_uae_arabic_people  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_label.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "12962f0e-dfc6-4d10-a930-38465d7c4ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_label.to_csv('bert_model_1_label_train_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6503841e-5b08-4e2a-9dba-8c5dc063d1af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
